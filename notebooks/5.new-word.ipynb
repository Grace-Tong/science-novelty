{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1115f982-33d2-43df-8ead-d407c3699112",
   "metadata": {},
   "source": [
    "# New word \n",
    "\n",
    "## Overview\n",
    "This notebook is designed for analyzing a dataset of papers to identify the new words.\n",
    "For each new word, the ID is the first paper is identified and the number of subsequent papers the re-use the word are counted.\n",
    "\n",
    "A baseline of words is defined. Words that appear in the baseline are not considered as new words. \n",
    "\n",
    "The script reads processed data from a CSV file, compares each word against the baseline, and counts the occurrences of the new words. The results are then written to a new CSV file.\n",
    "\n",
    "## Workflow\n",
    "- **Setting Up the Environment**: The script starts by importing necessary libraries and adjusting the system’s maximum integer size to avoid errors when reading large lines from the CSV file.\n",
    "\n",
    "- **Counting the Number of Papers:** It calculates the total number of papers to be processed by counting the lines in the processed data CSV file. This is needed to keep track of the process with a progress bar (tqdm).\n",
    "\n",
    "- **Creating the Baseline:** A baseline set of words is created from papers published before a specified baseline year. The notebook reads each paper and adds words to the baseline set if the paper’s publication year is before the baseline year.\n",
    "\n",
    "- **Counting New Words:** The notebook then reads the processed data of each paper and counts the occurrence of words that are not in the baseline set. Each new word’s count and the ID of the paper in which it first appeared are stored.\n",
    "\n",
    "- **Exporting the Results:** The counted new words, along with the ID of the paper in which each word first appeared and the total count of each word’s occurrence, are written to a new CSV file. Words that only appeared once are filtered out.\n",
    "\n",
    "## Output\n",
    "The notebook generates a CSV file containing each new word that is not part of the baseline, the ID of the paper in which the word first appeared, and the total count of the word’s occurrence in all papers. Each row in the file represents a unique new word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b58a646-da3b-4edf-ae4f-e355bc07213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "## Increase the max size of a line reading, otherwise an error is raised\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1447055c-b21a-4b07-b0f5-9f2173850cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the number of papers to process...\n",
      "Creating the baseline...\n",
      "Iterating over the baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee920b5bd60458ea1b67858f80d77f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb3ad097894494dbd0ab55c3d9b726e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a3e57323c94ca5892fb253f871e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3922 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Count the number of papers\n",
    "print('Get the number of papers to process...')\n",
    "with open('../data/processed/papers_words.csv', 'r', encoding='utf-8') as file:\n",
    "    line_count = sum(1 for line in file)\n",
    "total_papers = line_count - 1  # Subtract 1 for the header\n",
    "\n",
    "print('Creating the baseline...')\n",
    "# Creating a baseline set of words from papers published before the baseline year\n",
    "baseline_year = 2000\n",
    "baseline = set()\n",
    "\n",
    "print('Iterating over the baseline...')\n",
    "with open('../data/raw/papers_raw.csv', 'r', encoding='utf-8') as raw_reader, \\\n",
    "        open('../data/processed/papers_words.csv', 'r', encoding='utf-8') as processed_reader:\n",
    "        \n",
    "    csv_raw_reader = csv.reader(raw_reader, delimiter='\\t', quotechar='\"')\n",
    "    csv_processed_reader = csv.reader(processed_reader, delimiter=',', quotechar='\"')\n",
    "\n",
    "    # Skipping the headers\n",
    "    next(csv_raw_reader)\n",
    "    next(csv_processed_reader)\n",
    "    \n",
    "    # Iterating over each paper and adding words to the baseline if the paper was published before the baseline year\n",
    "    for line_raw, line_processed in tqdm(zip(csv_raw_reader, csv_processed_reader), total=total_papers):\n",
    "        if int(line_raw[1].split('-')[0]) > baseline_year:\n",
    "            continue\n",
    "            \n",
    "        text = set(line_processed[1].split() + line_processed[2].split())\n",
    "        baseline.update(text)\n",
    "        \n",
    "# Counting the occurrence of new words that are not in the baseline\n",
    "counter = collections.Counter()\n",
    "paperIds = collections.defaultdict()\n",
    "\n",
    "print('Calculating new words...')\n",
    "# Reading the processed papers data and counting new words\n",
    "with open('../data/processed/papers_words.csv', 'r', encoding='utf-8') as reader:\n",
    "    csv_reader = csv.reader(reader, delimiter=',', quotechar='\"')\n",
    "    next(csv_reader)  # Skip header\n",
    "\n",
    "    for line in tqdm(csv_reader, total=total_papers):\n",
    "        paperID = int(line[0])\n",
    "        text = set(line[1].split() + line[2].split())\n",
    "        \n",
    "        for token in text:\n",
    "            if token in baseline:\n",
    "                continue\n",
    "                \n",
    "            if token not in counter:\n",
    "                counter[token] = 0\n",
    "                paperIds[token] = paperID\n",
    "            else:\n",
    "                counter[token] += 1\n",
    "                \n",
    "print('Exporting the results...')\n",
    "# Exporting the results to a new CSV file\n",
    "with open('../data/metrics/new_word.csv', 'w', encoding=\"utf-8\") as writer:\n",
    "    writer.write('word,PaperID,reuse\\n') # Header\n",
    "\n",
    "    for token, paperID, reuse in tqdm(zip(counter.keys(), paperIds.values(), counter.values()), total=len(counter)):\n",
    "        # Filter out if reused only once\n",
    "        if reuse == 0:\n",
    "            continue\n",
    "\n",
    "        writer.write(f'{token},{paperID},{reuse}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
