{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1115f982-33d2-43df-8ead-d407c3699112",
   "metadata": {},
   "source": [
    "# New word comb\n",
    "\n",
    "## Overview\n",
    "This notebook is designed for analyzing a dataset of papers to identify the new word combinations.\n",
    "For each new word combination, the ID is the first paper is identified and the number of subsequent papers the re-use the word are counted.\n",
    "\n",
    "A baseline of word combinations is defined. Word combinations that appear in the baseline are not considered as new word combinations. \n",
    "\n",
    "The script reads processed data from a CSV file, compares each word combination against the baseline, and counts the occurrences of the new word combinations. The results are then written to a new CSV file.\n",
    "\n",
    "## Workflow\n",
    "- **Setting Up the Environment**: The script starts by importing necessary libraries and adjusting the system’s maximum integer size to avoid errors when reading large lines from the CSV file.\n",
    "\n",
    "- **Counting the Number of Papers:** It calculates the total number of papers to be processed by counting the lines in the processed data CSV file. This is needed to keep track of the process with a progress bar (tqdm).\n",
    "\n",
    "- **Creating the Baseline:** A baseline set of word combinations is created from papers published before a specified baseline year. The notebook reads each paper and adds word combinations to the baseline set if the paper’s publication year is before the baseline year.\n",
    "\n",
    "- **Counting New Words:** The notebook then reads the processed data of each paper and counts the occurrence of word combinations that are not in the baseline set. Each new word combination’s count and the ID of the paper in which it first appeared are stored.\n",
    "\n",
    "- **Exporting the Results:** The counted new word combinations, along with the ID of the paper in which each word combination first appeared and the total count of each word combinations’s occurrence, are written to a new CSV file. Word combinations that only appeared once are filtered out.\n",
    "\n",
    "## Output\n",
    "The notebook generates a CSV file containing each new word combination that is not part of the baseline, the ID of the paper in which the word combinations first appeared, and the total count of the word combination’s occurrence in all papers. Each row in the file represents a unique new word combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b58a646-da3b-4edf-ae4f-e355bc07213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import collections\n",
    "import sys\n",
    "import itertools as it\n",
    "\n",
    "## Increase the max size of a line reading, otherwise an error is raised\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1447055c-b21a-4b07-b0f5-9f2173850cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get the number of papers to process...\n",
      "Creating the baseline...\n",
      "Iterating over the baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3ad92a89094353b39b31e67d13a85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a9d42c2ae5480b9cf4a7d0cf6585a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the results...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f7d6dc6a294e4ba308ee0b58d1cfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Count the number of papers\n",
    "print('Get the number of papers to process...')\n",
    "with open('../data/processed/papers_words.csv', 'r', encoding='utf-8') as file:\n",
    "    line_count = sum(1 for line in file)\n",
    "total_papers = line_count - 1  # Subtract 1 for the header\n",
    "\n",
    "print('Creating the baseline...')\n",
    "# Creating a baseline set of words from papers published before the baseline year\n",
    "baseline_year = 2000\n",
    "baseline = set()\n",
    "\n",
    "print('Iterating over the baseline...')\n",
    "with open('../data/raw/papers_raw.csv', 'r', encoding='utf-8') as raw_reader, \\\n",
    "        open('../data/processed/papers_words.csv', 'r', encoding='utf-8') as processed_reader:\n",
    "        \n",
    "    csv_raw_reader = csv.reader(raw_reader, delimiter='\\t', quotechar='\"')\n",
    "    csv_processed_reader = csv.reader(processed_reader, delimiter=',', quotechar='\"')\n",
    "\n",
    "    # Skipping the headers\n",
    "    next(csv_raw_reader)\n",
    "    next(csv_processed_reader)\n",
    "    \n",
    "    # Iterating over each paper and adding words to the baseline if the paper was published before the baseline year\n",
    "    for line_raw, line_processed in tqdm(zip(csv_raw_reader, csv_processed_reader), total=total_papers):\n",
    "        if int(line_raw[1].split('-')[0]) > baseline_year:\n",
    "            continue\n",
    "            \n",
    "        text = set(line_processed[1].split() + line_processed[2].split())\n",
    "        \n",
    "        combs = list(it.combinations(text,2))\n",
    "        combs = set([tuple(sorted(comb)) for comb in combs])\n",
    "        \n",
    "        baseline.update(combs)\n",
    "        \n",
    "# Counting the occurrence of new words that are not in the baseline\n",
    "counter = collections.Counter()\n",
    "paperIds = collections.defaultdict()\n",
    "\n",
    "print('Calculating new words...')\n",
    "# Reading the processed papers data and counting new words\n",
    "with open('../data/processed/papers_words.csv', 'r', encoding='utf-8') as reader:\n",
    "    csv_reader = csv.reader(reader, delimiter=',', quotechar='\"')\n",
    "    next(csv_reader)  # Skip header\n",
    "\n",
    "    for line in tqdm(csv_reader, total=total_papers):\n",
    "        paperID = int(line[0])\n",
    "        text = set(line[1].split() + line[2].split())\n",
    "        \n",
    "        combs = list(it.combinations(text,2))\n",
    "        combs = set([tuple(sorted(comb)) for comb in combs])\n",
    "        \n",
    "        for comb in combs:\n",
    "            if comb in baseline:\n",
    "                continue\n",
    "                \n",
    "            if comb not in counter:\n",
    "                counter[comb] = 0\n",
    "                paperIds[comb] = paperID\n",
    "            else:\n",
    "                counter[comb] += 1\n",
    "                \n",
    "print('Exporting the results...')\n",
    "# Exporting the results to a new CSV file\n",
    "with open('../data/metrics/new_word_comb.csv', 'w', encoding=\"utf-8\") as writer:\n",
    "    writer.write('word1,word2,PaperID,reuse\\n') # Header\n",
    "\n",
    "    for (word1, word2), paperID, reuse in tqdm(zip(counter.keys(), paperIds.values(), counter.values()), total=len(counter)):\n",
    "        # Filter out if reused only once\n",
    "        if reuse == 0:\n",
    "            continue\n",
    "\n",
    "        writer.write(f'{word1},{word2},{paperID},{reuse}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
