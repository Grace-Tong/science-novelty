{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff931b70-10ed-41f3-aa5f-afa93acc352a",
   "metadata": {},
   "source": [
    "# Cosine Distance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a60a37-eda8-4da2-aff7-f485cf627e50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "The notebook is designed to process and analyze a collection of papers represented by their embedding vector data over a series of years. It calculates the cosine similarities between the vectors of papers for a given year and those from the previous five years, aiming to measure the similarity in content. The results, including the average and maximum cosine similarities for each paper, are then saved to a CSV file for further analysis or reference.\n",
    "The code is optimized to run it on the GPU if available.\n",
    "\n",
    "## Workflow\n",
    "- **Loading Data**: The notebook starts by loading vector data of papers for a specific year from a designated directory. Each row in the data files corresponds to a paper, with one column representing the paper's ID and the remaining columns representing the vector.\n",
    "\n",
    "> **_NOTE:_**  All vectors are assumed to be stored in csv files divided by years.\n",
    "\n",
    "- **Data Segmentation**: To optimize memory usage, the data is divided into manageable chunks. This segmentation facilitates efficient processing, especially for large datasets.\n",
    "\n",
    "- **Rolling Data Collection**: The vector data for the current year is added to a rolling collection that holds the data for the current and previous five years. This rolling mechanism ensures that only the most relevant five years of data are considered at any given time.\n",
    "\n",
    "- **Cosine Similarity Calculation**: If there are at least six years of data in the rolling collection, the notebook proceeds to calculate the cosine similarities. It compares the vectors of the current year’s papers with the combined vectors of the papers from the previous five years.\n",
    "\n",
    "- **Average and Maximum Similarities**: For each paper in the current year, both the average and maximum cosine similarities are calculated in relation to the papers from the previous years.\n",
    "\n",
    "- **Result Storage**: The calculated average and maximum cosine similarities, along with the paper IDs, are saved to a CSV file.\n",
    "\n",
    "- **Iteration**: The notebook repeats this process for each year in the specified range, ensuring that each year’s data is compared with the data from its preceding years.\n",
    "\n",
    "## Note\n",
    "\n",
    "- Ensure `cupy` is installed to run on GPU, you can install it via `pip install cupy`.\n",
    "- Adjust the CHUNK_SIZE based on GPU memory availability if running on GPU.\n",
    "- This notebook assumes that vectors are stored in consecutive years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0901020c-150c-407c-8ff5-9d9777e85096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "\n",
    "# Try to import cupy for GPU acceleration, fall back to numpy if not available\n",
    "try:\n",
    "    import cupy as xp\n",
    "    print(\"Running on GPU\")\n",
    "except ImportError:\n",
    "    import numpy as xp\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "# Constants\n",
    "path_vectors = '../data/vectors/'\n",
    "CHUNK_SIZE = 1000  # Adjust based on memory availability\n",
    "OUTPUT_PATH = '../data/metrics/papers_cosine.csv'  # Adjust this path as needed\n",
    "N_JOBS = -1  # Use all available cores\n",
    "\n",
    "def load_vectors_for_year(year):\n",
    "    \"\"\"Load vectors for a specific year using efficient reading.\"\"\"\n",
    "    \n",
    "    file_path = os.path.join(path_vectors, f\"{year}_vectors.csv\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return None, None\n",
    "    \n",
    "    print(f'Reading {year}...')\n",
    "    # Load the entire CSV into a single numpy array\n",
    "    data = xp.loadtxt(file_path, delimiter=',', dtype=np.float32, skiprows = 1)\n",
    "    \n",
    "    # Check if there is only one paper in the year\n",
    "    if len(data) == 769:\n",
    "        papers_ids = [data[0].astype(xp.int64)]\n",
    "        vectors = [data[1:]]\n",
    "        \n",
    "    else:\n",
    "        # Slice the array to get the desired columns\n",
    "        papers_ids = data[:, 0].astype(xp.int64)  # Assuming the first column is the PaperId\n",
    "        vectors = data[:, 1:]  # Assuming the rest of the columns are the vectors\n",
    "\n",
    "    return papers_ids, vectors\n",
    "\n",
    "def cosine_similarity(vector_a, vector_b):\n",
    "    \"\"\"Simple cosine similarity function\"\"\"\n",
    "    \n",
    "    norm_a = xp.linalg.norm(vector_a)\n",
    "    norm_b = xp.linalg.norm(vector_b)\n",
    "    \n",
    "    dot_product = xp.dot(vector_a, vector_b)\n",
    "    \n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def calculate_similarity_for_chunk(chunk, prior_data):\n",
    "    \"\"\"Calculate similarity for a chunk using matrix multiplication.\"\"\"\n",
    "    # Normalize the vectors\n",
    "    chunk_norm = chunk / xp.linalg.norm(chunk, axis=1, keepdims=True)\n",
    "    prior_data_norm = prior_data / xp.linalg.norm(prior_data, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute cosine similarities using matrix multiplication\n",
    "    similarities = xp.dot(chunk_norm, prior_data_norm.T)\n",
    "    \n",
    "    avg_dists = xp.mean(similarities, axis=1)\n",
    "    max_dists = xp.max(similarities, axis=1)\n",
    "    \n",
    "    return avg_dists, max_dists\n",
    "\n",
    "def calculate_avg_max_similarity(current_data, prior_data):\n",
    "    \"\"\"Calculate average and max cosine similarities for chunks.\"\"\"\n",
    "    results = Parallel(n_jobs=N_JOBS)(\n",
    "        delayed(calculate_similarity_for_chunk)(current_data[i:i+CHUNK_SIZE], prior_data)\n",
    "        for i in tqdm(range(0, len(current_data), CHUNK_SIZE))\n",
    "    )\n",
    "    avg_similarities = xp.concatenate([res[0] for res in results])\n",
    "    max_similarities = xp.concatenate([res[1] for res in results])\n",
    "    return avg_similarities, max_similarities\n",
    "\n",
    "def initialize_output_file():\n",
    "    \"\"\"Initialize the output CSV file with headers.\"\"\"\n",
    "    with open(OUTPUT_PATH, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['PaperId', 'cosine_max', 'cosine_avg'])\n",
    "\n",
    "def save_to_csv(papers_ids, avg_similarities, max_similarities):\n",
    "    \"\"\"Append results to CSV.\"\"\"\n",
    "    with open(OUTPUT_PATH, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for paper_id, avg_sim, max_sim in zip(papers_ids, avg_similarities, max_similarities):\n",
    "            writer.writerow([paper_id, max_sim, avg_sim])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc012c4-9ca6-4e6c-ad4c-ea62cb497b18",
   "metadata": {},
   "source": [
    "### Define the years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4043583-a842-4545-a7c3-cede7710d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1851\n",
    "end_year = 1999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b13f5-20d8-42e9-8dc4-612007d2c6be",
   "metadata": {},
   "source": [
    "### Run the similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e3ff77d-c192-462b-8720-0fc12f5e89da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04cbdd6983f4526994a21c5c5b5f41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1851...\n",
      "Reading 1900...\n",
      "Reading 1906...\n",
      "Reading 1969...\n",
      "Reading 1974...\n",
      "Reading 1976...\n",
      "Reading 1980...\n",
      "Reading 1983...\n",
      "Reading 1984...\n",
      "Reading 1985...\n",
      "Reading 1986...\n",
      "Reading 1987...\n",
      "Reading 1988...\n",
      "Calculating similarities for 1988...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca37493cebbb4c9c8d93eef07efb218c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1989...\n",
      "Calculating similarities for 1989...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d435c97667b747c38caa1865132e9d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1990...\n",
      "Calculating similarities for 1990...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344766891b5942f3a6ddb6fc473b4f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1991...\n",
      "Calculating similarities for 1991...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7771bfec5004e42905f619d9f1d0bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1992...\n",
      "Calculating similarities for 1992...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6198a040a2d44b58a51eab9c82e4b59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1993...\n",
      "Calculating similarities for 1993...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ad280f4c32423d907e504b86013e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1994...\n",
      "Calculating similarities for 1994...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46f4255381d4a18b46b2f28d0a2d3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1995...\n",
      "Calculating similarities for 1995...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3057e4666f6e4ec29d8e44df64b300be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1996...\n",
      "Calculating similarities for 1996...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f123473fa7b34ffdbfca072a239c56d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1997...\n",
      "Calculating similarities for 1997...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cb34346fb14af8a27b25f3b9e93665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1998...\n",
      "Calculating similarities for 1998...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158270aee28440f88dba3e5f1e589df9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1999...\n",
      "Calculating similarities for 1999...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d096d5611c4dbbb87981ffe3efd194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rolling_data = []\n",
    "years = range(start_year, end_year + 1) # +1 to include the last year\n",
    "\n",
    "# Initialize the output CSV file\n",
    "initialize_output_file()\n",
    "\n",
    "for year in tqdm(years):\n",
    "    papers_ids, current_year_data = load_vectors_for_year(year)\n",
    "    \n",
    "    if current_year_data is None:\n",
    "        continue\n",
    "\n",
    "    # Add current year data to rolling data\n",
    "    rolling_data.append((year, current_year_data))\n",
    "    \n",
    "    # Remove data that is more than 5 years old\n",
    "    rolling_data = [(y, data) for y, data in rolling_data if year - y < 6]\n",
    "\n",
    "    # If there's not enough prior data, skip the calculations for this year\n",
    "    if len(rolling_data) < 6:\n",
    "        continue\n",
    "\n",
    "    # Combine prior years data\n",
    "    prior_data = xp.vstack([data for y, data in rolling_data if y != year])\n",
    "    \n",
    "    print('Calculating similarities for %d...'%(year))\n",
    "    # Calculate cosine similarities\n",
    "    avg_year_similarities, max_year_similarities = calculate_avg_max_similarity(current_year_data, prior_data)\n",
    "\n",
    "    # Save results to CSV\n",
    "    save_to_csv(papers_ids, avg_year_similarities, max_year_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dec4c2a2-4522-4e35-b0b9-ad31716f5d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prior_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\9/ipykernel_29976/1369382377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprior_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prior_data' is not defined"
     ]
    }
   ],
   "source": [
    "prior_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec7185a-8807-40b4-b467-55c396563b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\9/ipykernel_29976/216286669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpapers_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#.astype(xp.int64)  # Assuming the first column is the PaperId\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Assuming the rest of the columns are the vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(path_vectors, f\"{year}_vectors.csv\")\n",
    "\n",
    "# Load the entire CSV into a single numpy array\n",
    "data = xp.loadtxt(file_path, delimiter=',', dtype=np.float32, skiprows = 1)\n",
    "data\n",
    "\n",
    "papers_ids = data[:, 0]#.astype(xp.int64)  # Assuming the first column is the PaperId\n",
    "vectors = data[:, 1:]  # Assuming the rest of the columns are the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f583a890-25d6-4316-a46f-433c12389bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
