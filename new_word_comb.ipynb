{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86ff862-a28e-45ac-a98c-3e74f9935131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b383579c3c40d297a4177171775a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()\n",
    "import numpy as np\n",
    "\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "path = 'D:/Users/Nicola Melluso/ScientificPublications/'\n",
    "path_vectors = path + 'Papers/TitleAbstract/papers_vectors/'\n",
    "\n",
    "path_processed = path + 'PapersProcessed/'\n",
    "\n",
    "gram = 'unigrams'\n",
    "gram_label = gram + '_comb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712052ff-7ac7-4acf-b21b-571a3d9f5261",
   "metadata": {},
   "source": [
    "## ************** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b2bf5-49ab-4b7f-9068-58361dfcb37f",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff465883-9c9d-4f9d-8f16-79e20f262998",
   "metadata": {},
   "source": [
    "### 1. Papers to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c150d52f-25e4-4dba-99af-4dbe285ce90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd441a34e9444c1289cef5ea26ad69dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72245396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b147d06691f4708b2bafdbc7a9cdb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33536292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = open('./data/paperIds.txt','r')\n",
    "paperIds = set()\n",
    "\n",
    "for line in tqdm(reader,total = 72245396):\n",
    "    paperIds.add(int(line.replace('\\n','')))\n",
    "    \n",
    "\n",
    "reader = open('./data/paperIdsNov.txt','r')\n",
    "paperIdsNov = set()\n",
    "\n",
    "for line in tqdm(reader,total = 33536292):\n",
    "    paperIdsNov.add(int(line.replace('\\n','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c594db-8fd1-4d86-9efa-14713c77c9c4",
   "metadata": {},
   "source": [
    "### 2. Gram to idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c68c29b-fbf0-4433-b7af-6d97d9b95eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd398797f1ba4aeda57676f9851143fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7363821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = open('./data/%s_to_idx.csv'%(gram),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "gram_to_idx = {}\n",
    "idx_to_gram = {}\n",
    "\n",
    "for line in tqdm(reader, total = 7363821):\n",
    "    \n",
    "    if ',' not in line:\n",
    "        continue\n",
    "        \n",
    "    line = line.split(',')\n",
    "    try:\n",
    "        gram_to_idx[line[0]] = int(line[1].replace('\\n',''))\n",
    "        idx_to_gram[int(line[1].replace('\\n',''))] = line[0]\n",
    "    except Exception:\n",
    "        continue\n",
    "        \n",
    "del gram_to_idx['']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce762d3b-32b7-4fd1-a5f0-16d459320736",
   "metadata": {},
   "source": [
    "### 3. Core analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe1476dc-8851-4768-b266-820a01fff2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af9d05cdc2943ebb05df3b7dfda4034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10809447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2d22f565da4ebabc89906c2a4ee17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10172374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808812a11c494b689a83d7bb5f058f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103061513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the counter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e44909a9264728a951d56fe9c8de57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2579272666 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Reading baseline...')\n",
    "baseline = set()\n",
    "\n",
    "reader = open(path_processed + '%s_baseline.txt'%(gram_label),'r', encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(reader, total = 10809447):\n",
    "    \n",
    "    baseline.add(tuple(sorted([int(i) for i in line.replace('\\n','').split(',')])))\n",
    "\n",
    "# remove empty space combinations\n",
    "baseline = set([i for i in tqdm(baseline) if 1 not in i])\n",
    "        \n",
    "print('Analysis...')\n",
    "\n",
    "reader = open('./data/%s.csv'%(gram.split('_')[0]),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_paperId.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,PaperId\\n')\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for line in tqdm(reader, total = 103061513):\n",
    "    \n",
    "    line = line.split('\\t')\n",
    "    \n",
    "    paperId = int(line[0])\n",
    "    \n",
    "    if paperId not in paperIds:\n",
    "        continue\n",
    "                \n",
    "    text = set(' '.join(line[1:]).split(' '))\n",
    "    text = [gram_to_idx.get(t) for t in text]\n",
    "    text = set([t for t in text if t is not None])\n",
    "\n",
    "    combs = list(it.combinations(text,2))\n",
    "\n",
    "    combs = [c for c in combs if c not in baseline]\n",
    "    \n",
    "    for comb in combs:\n",
    "        comb = tuple(sorted(comb))\n",
    "        if comb not in counter:\n",
    "            if paperId not in paperIdsNov:\n",
    "                continue\n",
    "            \n",
    "            counter[comb] = 0\n",
    "            \n",
    "            ## write the PaperId\n",
    "            writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    comb[0],\n",
    "                    comb[1],\n",
    "                    paperId\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "        else:\n",
    "            counter[comb] += 1\n",
    "            \n",
    "writer.close()\n",
    "    \n",
    "print('Exporting the counter...')\n",
    "writer = open('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,reuse\\n')\n",
    "\n",
    "for comb,reuse in tqdm(counter.items(), total = len(counter)):\n",
    "    writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    comb[0],\n",
    "                    comb[1],\n",
    "                    reuse\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795df3a9-ba49-47f0-9e73-9153bb5165cf",
   "metadata": {},
   "source": [
    "## 2. Adjust non-doi and citations minimum count "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626e6b9-d4d0-4052-9b3d-645660bd60d1",
   "metadata": {},
   "source": [
    "#### Read grams with only reuse > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f89a58-6a48-4b7b-b3d1-6f3bfeac0dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5881bed8ae4f4394acaf15df8a3d8fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2579272666 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#counter = set()\n",
    "combinations = {}\n",
    "\n",
    "reader = open('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "for line in tqdm(reader, total = 2579272666):\n",
    "    line = line.split(',')\n",
    "    \n",
    "    reuse = int(line[2].replace('\\n',''))\n",
    "    \n",
    "    if reuse <= 5:\n",
    "        continue\n",
    "        \n",
    "    comb = (int(line[0]),int(line[1]))\n",
    "    \n",
    "    combinations[comb] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b5975-443e-4e3c-9377-0c1c8139363c",
   "metadata": {},
   "source": [
    "### Re-do analysis \n",
    "\n",
    "Create a new file `new_gram_PaperId_DC.csv` with the real PaperIds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f7f2ca-065e-49c0-8774-cb428e9ac9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2549ad858d7a4a538db26ead2b1424cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10809447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2/ipykernel_16624/3615550927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_processed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'%s_baseline.txt'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgram_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10809447\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mbaseline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Reading baseline...')\n",
    "baseline = set()\n",
    "dones = set()\n",
    "counter = Counter()\n",
    "\n",
    "reader = open(path_processed + '%s_baseline.txt'%(gram_label),'r', encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(reader, total = 10809447):\n",
    "    \n",
    "    baseline.add(tuple(sorted([int(i) for i in line.replace('\\n','').split(',')])))\n",
    "\n",
    "# remove empty space combinations\n",
    "baseline = set([i for i in tqdm(baseline) if 1 not in i])\n",
    "\n",
    "print('Analysis...')\n",
    "\n",
    "reader = open('./data/%s.csv'%(gram.split('_')[0]),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_paperId_DC.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,PaperId\\n')\n",
    "\n",
    "\n",
    "for line in tqdm(reader, total = 103117245):\n",
    "    \n",
    "    line = line.split('\\t')\n",
    "    \n",
    "    paperId = int(line[0])\n",
    "    \n",
    "    if paperId not in paperIds:\n",
    "        continue\n",
    "                \n",
    "    text = set(' '.join(line[1:]).split(' '))\n",
    "    text = [gram_to_idx.get(t) for t in text]\n",
    "    text = [t for t in text if t is not None]\n",
    "\n",
    "    combs = list(it.combinations(text,2))\n",
    "\n",
    "    combs = [c for c in combs if c not in baseline]\n",
    "    \n",
    "    for comb in combs:\n",
    "        \n",
    "        comb = tuple(sorted(comb))\n",
    "        \n",
    "        if comb not in combinations:\n",
    "            if comb not in counter:\n",
    "            \n",
    "                ## write the PaperId real\n",
    "                writer.write(','.join([\n",
    "                    str(i) for i in [\n",
    "                        comb[0],\n",
    "                        comb[1],\n",
    "                        paperId\n",
    "                    ]\n",
    "                ]) + '\\n')\n",
    "                \n",
    "                counter[comb] = 0\n",
    "            else:\n",
    "                counter[comb] += 1\n",
    "                \n",
    "writer.close()\n",
    "reader.close()\n",
    "\n",
    "print('Exporting the counter...')\n",
    "writer = open('./data/new_%s/new_%s_reuse_DC.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,reuse\\n')\n",
    "\n",
    "for comb,reuse in tqdm(counter.items(), total = len(counter)):\n",
    "    writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    comb[0],\n",
    "                    comb[1],\n",
    "                    reuse\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "    \n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eba56f5c-0ab5-46ee-bce2-26080defa5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the counter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2328ec35b32d427eb84272d80f45b410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863311530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Exporting the counter...')\n",
    "writer = open('./data/new_%s/new_%s_reuse_DC.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,reuse\\n')\n",
    "\n",
    "for comb,reuse in tqdm(counter.items(), total = len(counter)):\n",
    "    writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    comb[0],\n",
    "                    comb[1],\n",
    "                    reuse\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfeb08-7ca6-4104-b164-070722a6e5a7",
   "metadata": {},
   "source": [
    "# ********* Re-start kernel ********** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9becb719-d145-48ce-9e28-8272238958be",
   "metadata": {},
   "source": [
    "# Aggregations \n",
    "### To execute after the counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4ee07-8124-4e1f-bda4-70bae8ebee19",
   "metadata": {},
   "source": [
    "## Merging new word combs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7007b6e4-09ba-4ca5-918d-4add2d8745bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Reading papers...')\n",
    "papers = pd.read_csv('./data/PapersData.csv', converters = {'PaperId':int}, usecols = ['PaperId'])\n",
    "\n",
    "stop_index = papers[papers['PaperId'] == 2221882060].index[0]\n",
    "print('Creating papersId set...')\n",
    "paperIds = set(papers[stop_index:]['PaperId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43018116-0cc5-42f1-919b-e02a4c417396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1244b3487a9c451b8cac00813083f0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gram_label = 'unigrams_comb'\n",
    "writer = open('./data/new_%s/new_%s_gram_idx.csv'%(gram_label,gram_label), 'w')\n",
    "writer.write('gram_idx_1,gram_idx_2,PaperId,reuse\\n')\n",
    "\n",
    "combs_reuse = open('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label),  encoding=\"utf-8\")\n",
    "combs_paperId = open('./data/new_%s/new_%s_PaperId.csv'%(gram_label,gram_label),  encoding=\"utf-8\")\n",
    "\n",
    "combs_reuse.__next__()\n",
    "combs_paperId.__next__()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for line_reuse,line_paperId in tqdm(zip(combs_reuse, combs_paperId)):\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    line_reuse = line_reuse.replace('\\n','').split(',')\n",
    "    reuse = int(line_reuse[-1])\n",
    "    paperId = int(line_reuse[2])\n",
    "    \n",
    "    \n",
    "    ## random check\n",
    "    if i % 1000000 == 0:\n",
    "        assert line_reuse[0] == line_paperId.split(',')[0]\n",
    "        assert line_reuse[1] == line_paperId.split(',')[1]\n",
    "    \n",
    "    \n",
    "    if reuse <= 5:\n",
    "        if paperId in paperIds:\n",
    "            writer.write(line_paperId.replace('\\n',',') + str(reuse) + '\\n')\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    writer.write(line_paperId.replace('\\n',',') + str(reuse) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71833416-6bbd-4453-952d-d19073579b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae77d818fd6a440bb6a2d1309b91bd80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2863311530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gram_label = 'unigrams_comb'\n",
    "writer = open('./data/new_%s/new_%s_gram_idx.csv'%(gram_label,gram_label), 'a')\n",
    "#writer.write('gram_idx_1,gram_idx_2,PaperId,reuse\\n')\n",
    "\n",
    "combs_reuse = open('./data/new_%s/new_%s_reuse_DC.csv'%(gram_label,gram_label),  encoding=\"utf-8\")\n",
    "combs_paperId = open('./data/new_%s/new_%s_PaperId_DC.csv'%(gram_label,gram_label),  encoding=\"utf-8\")\n",
    "\n",
    "combs_reuse.__next__()\n",
    "combs_paperId.__next__()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for line_reuse,line_paperId in tqdm(zip(combs_reuse, combs_paperId), total = 2863311530):\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    line_reuse = line_reuse.replace('\\n','').split(',')\n",
    "    reuse = int(line_reuse[-1])\n",
    "    paperId = int(line_reuse[2])\n",
    "    \n",
    "    \n",
    "    ## random check\n",
    "    if i % 1000000 == 0:\n",
    "        assert line_reuse[0] == line_paperId.split(',')[0]\n",
    "        assert line_reuse[1] == line_paperId.split(',')[1]\n",
    "    \n",
    "    \n",
    "    if reuse == 0:\n",
    "        continue\n",
    "        \n",
    "    writer.write(line_paperId.replace('\\n',',') + str(reuse) + '\\n')\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48974100-8101-4dd6-8342-b13f35504395",
   "metadata": {},
   "source": [
    "#### Gram to idx for word combs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ef2b948-a6df-4d27-b2df-7f5956851ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c40d9707d44c40b43004fbb76daaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = open('./data/new_%s/new_%s.csv'%(gram_label,gram_label), 'w')\n",
    "writer.write('word1,word2,PaperId,reuse\\n')\n",
    "\n",
    "reader = open('./data/new_%s/new_%s_gram_idx.csv'%(gram_label,gram_label), 'r')\n",
    "reader.__next__()\n",
    "\n",
    "for line in tqdm(reader):\n",
    "    line = line.split(',')\n",
    "    line[0] = idx_to_gram[int(line[0])]\n",
    "    line[1] = idx_to_gram[int(line[1])]\n",
    "    \n",
    "    writer.write(','.join(line))\n",
    "    \n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2d722-592a-4145-88a2-1f849abd66d7",
   "metadata": {},
   "source": [
    "Chunking strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02ec349-04aa-40bf-8653-b98f1d12c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdb378207d44c11bac247606b3a9b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20880952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = open('./data/%s_to_idx.csv'%(gram),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "idx_to_gram = {}\n",
    "\n",
    "for line in tqdm(reader, total = 20880952):\n",
    "    \n",
    "    if ',' not in line:\n",
    "        continue\n",
    "        \n",
    "    line = line.split(',')\n",
    "#    idx_to_gram[int(line[1].replace('\\n',''))] = line[0]\n",
    "    \n",
    "    try:\n",
    "        idx_to_gram[line[1]] = int(line[0].replace('\\n',''))\n",
    "    except Exception:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97893857-41d1-4656-b519-50b14905aaab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fffd54-0a79-418d-a403-20c358ab8951",
   "metadata": {},
   "source": [
    "### Adjust for fixing the issue wiith memory\n",
    "There are combinations that appear in all papers (non-DOI and citations < 5) and are re-used less than 5 times that are not counted for papers after 2015 (specifically after the paperId 2221882060).\n",
    "For combinations that appear after 2015 with re-use lower than 5, consider only the ones that come from papers with DOI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ae397a-cdf6-457b-a749-f911856330e1",
   "metadata": {},
   "source": [
    "> 5 or in PaperIds > of the order  2221882060"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d715e3-4254-4445-a9ee-c50151958de1",
   "metadata": {},
   "source": [
    "#### PaperId sorted by date: set of patents after the 2221882060"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0c05d-4a1a-47d7-8295-31ff301247f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Stopping PaperId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0fd5fa-706b-4a1c-9277-9242e233c842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2221882060"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperId_stop = 2221882060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80774e45-c81e-4e2b-914a-9296b2e01c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1967467172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2034577926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2070022537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3139928427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2073390270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72245391</th>\n",
       "      <td>3113519567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72245392</th>\n",
       "      <td>3117632671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72245393</th>\n",
       "      <td>2934725299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72245394</th>\n",
       "      <td>3090313612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72245395</th>\n",
       "      <td>3096692197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72245396 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PaperId\n",
       "0         1967467172\n",
       "1         2034577926\n",
       "2         2070022537\n",
       "3         3139928427\n",
       "4         2073390270\n",
       "...              ...\n",
       "72245391  3113519567\n",
       "72245392  3117632671\n",
       "72245393  2934725299\n",
       "72245394  3090313612\n",
       "72245395  3096692197\n",
       "\n",
       "[72245396 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv('./data/PapersData.csv', converters = {'PaperId':int}, usecols = ['PaperId'])\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54be2aca-0c48-4df6-a961-5c68ddc9e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv('./data/PapersData.csv', converters = {'PaperId':int}, usecols = ['PaperId'])\n",
    "\n",
    "stop_index = papers[papers['PaperId'] == 2221882060].index[0]\n",
    "paperIds = set(papers[stop_index:]['PaperId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557d15f-f513-4a22-9026-a031c765e143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First iterate over all...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43b111d080443f9ba5628a79826d263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b22fe5fc15e4777b0075048f3e45c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'paperIds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_paperId,df_reuse, on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgram1_idx\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgram2_idx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     34\u001b[0m dones_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaperId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m---> 36\u001b[0m df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m|\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[43mpaperIds\u001b[49m))]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paperIds' is not defined"
     ]
    }
   ],
   "source": [
    "chunksize = 1000000000\n",
    "\n",
    "ds_paperId = pd.read_csv('./data/new_%s/new_%s_paperId.csv'%(gram_label,gram_label), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_2.csv'%(gram_label,gram_label),'w')\n",
    "writer.write('word1,word2,PaperId,reuse\\n')\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "print('First iterate over all...')\n",
    "# iterate over paperIds\n",
    "for df_paperId in tqdm(ds_paperId, total = round(2579272666/chunksize)):\n",
    "    \n",
    "    reuses_dones = [-1]\n",
    "    \n",
    "    to_do_ids = set(list(df_paperId['PaperId'].unique()))\n",
    "    \n",
    "    if to_do_ids == set():\n",
    "        continue\n",
    "\n",
    "    ds_reuse = pd.read_csv('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "        \n",
    "    for i_reuse,df_reuse in tqdm(enumerate(ds_reuse)):\n",
    "        \n",
    "        if i_reuse <= max(reuses_dones):\n",
    "            continue\n",
    "        \n",
    "        #df_reuse = df_reuse[(df_reuse['reuse'] > 5) | (df_reuse['reuse'].isin(paperIds))]\n",
    "        \n",
    "        df = pd.merge(df_paperId,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "        \n",
    "        dones_ids = set(df['PaperId'].unique())\n",
    "        \n",
    "        df = df[(df['reuse'] > 5) | (df['reuse'].isin(paperIds))]\n",
    "                    \n",
    "        if df.empty:\n",
    "            continue\n",
    "            \n",
    "\n",
    "        df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "        df = df[['word1','word2','PaperId','reuse']]\n",
    "\n",
    "        df.to_csv('./data/new_%s/new_%s.csv'%(gram_label,gram_label), mode = 'a', header = False, index = False)\n",
    "        \n",
    "        \n",
    "        to_do_ids = to_do_ids - dones_ids\n",
    "\n",
    "        if to_do_ids == set():\n",
    "            reuses_dones.append(i_reuse)\n",
    "            break\n",
    "    \n",
    "print('Second iterate over non-DOI and citation minimum...')\n",
    "\n",
    "ds_paperId_DC = pd.read_csv('./data/new_%s/new_%s_paperId_DC.csv'%(gram_label,gram_label), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "\n",
    "for df_paperId_DC in tqdm(ds_paperId_DC, total = round(2863311530/chunksize)):\n",
    "    \n",
    "    reuses_dones = [-1]\n",
    "    \n",
    "    to_do_ids = set(list(df_paperId_DC['PaperId'].unique()))\n",
    "    \n",
    "    if to_do_ids == set():\n",
    "        continue\n",
    "    \n",
    "    ds_reuse = pd.read_csv('./data/new_%s/new_%s_reuse_DC.csv'%(gram,gram), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int}, encoding=\"utf-8\")\n",
    "    \n",
    "    for i_reuse, df_reuse in tqdm(enumerate(ds_reuse)):\n",
    "        \n",
    "        if i_reuse <= max(reuses_dones):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        df = pd.merge(df_paperId_DC,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "        \n",
    "        dones_ids = set(df['PaperId'].unique())\n",
    "        \n",
    "        df = df[df['reuse'] > 0]\n",
    "        \n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        \n",
    "        df = df[['word1','word2','PaperId','reuse']]\n",
    "        \n",
    "        df.to_csv('./data/new_%s/new_%s.csv'%(gram_label,gram_label), mode = 'a', header = False, index = False)     \n",
    "        \n",
    "        \n",
    "        to_do_ids = to_do_ids - dones_ids\n",
    "        \n",
    "        if to_do_ids == set():\n",
    "            reuses_dones.append(i_reuse)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf81217-3715-4efe-9f87-d4efef8b548f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Large memory batch \n",
    "#### 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f33e8-8ec5-4b47-97ac-38a7a3121e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PaperIds...\n",
      "Reading combs reuse...\n",
      "Reading combs paperId...\n",
      "Converting PaperId...\n",
      "Merging...\n"
     ]
    }
   ],
   "source": [
    "print('Reading PaperIds...')\n",
    "papers = pd.read_csv('./data/PapersData.csv', converters = {'PaperId':int}, usecols = ['PaperId'])\n",
    "\n",
    "stop_index = papers[papers['PaperId'] == 2221882060].index[0]\n",
    "paperIds = set(papers[stop_index:]['PaperId'].unique())\n",
    "\n",
    "print('Reading combs reuse...')\n",
    "df_reuse = pd.read_csv('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label), converters={'PaperId': int, 'gram1_idx':int, 'gram2_idx':int, 'reuse': int},  encoding=\"utf-8\")\n",
    "df_reuse = df_reuse[df_reuse['reuse'] > 5]\n",
    "\n",
    "# Define the filtering condition for \"PaperId\"\n",
    "filter_condition = lambda x: int(x) if int(x) not in paperIds else 0\n",
    "\n",
    "print('Reading combs paperId...')\n",
    "df_paperId = pd.read_csv('./data/new_%s/new_%s_paperId.csv'%(gram_label,gram_label), converters = {'PaperId':filter_condition,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "print('Converting PaperId...')\n",
    "df_paperId = df_paperId[df_paperId['PaperId'] != 0]\n",
    "\n",
    "print('Merging...')\n",
    "df = pd.merge(df_paperId,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "\n",
    "print('Converting grams...')\n",
    "df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "df = df[['word1','word2','PaperId','reuse']]\n",
    "\n",
    "print('Exporting...')\n",
    "df.to_csv('./data/new_%s/new_%s_2.csv'%(gram_label,gram_label), index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557608ca-38f5-4863-8631-40a47b5313d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ---- restart kernel ----- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a2167-f58e-4473-8202-be665e9650e6",
   "metadata": {},
   "source": [
    "#### 2nd iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09da29-55ad-4978-af25-a2ec2628b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading combs reuse...')\n",
    "df_reuse = pd.read_csv('./data/new_%s/new_%s_reuse_DC.csv'%(gram_label,gram_label), converters={'PaperId': int, 'gram1_idx':int, 'gram2_idx':int, 'reuse': int},  encoding=\"utf-8\")\n",
    "df_reuse = df_reuse[df_reuse['reuse'] > 0]\n",
    "\n",
    "print('Reading combs paperId...')\n",
    "df_paperId = pd.read_csv('./data/new_%s/new_%s_paperId_DC.csv'%(gram_label,gram_label), converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "print('Converting PaperId...')\n",
    "\n",
    "print('Merging...')\n",
    "df = pd.merge(df_paperId,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "\n",
    "print('Converting grams...')\n",
    "df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "df = df[['word1','word2','PaperId','reuse']]\n",
    "\n",
    "print('Exporting...')\n",
    "df.to_csv('./data/new_%s/new_%s_2.csv'%(gram_label,gram_label), mode = 'a', header = False, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c65e58-7068-4087-8398-bd17a8f264cb",
   "metadata": {},
   "source": [
    "## ******* Preliminary ********* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a5141-8268-4884-b3aa-d048648a2d94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2B. Define baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea810eeb-92bb-4ee7-84ed-7c759266482e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = range(1880,1901)\n",
    "\n",
    "baseline = set()\n",
    "baseline_title = set()\n",
    "\n",
    "for year in tqdm(years, total = len(years)):\n",
    "    df = pd.read_parquet(path_processed + gram + '/%d.parquet'%(year))\n",
    "    \n",
    "    df = df[df['Flag'] == 'Green'].fillna('')\n",
    "    \n",
    "    df[gram] = df[gram].apply(lambda x: [gram_to_idx.get(t) for t in list(set(x.split(' ')))])\n",
    "    df[gram] = df[gram].apply(lambda x: set([t for t in x if t is not None]))\n",
    "    \n",
    "    df[gram + '_title'] = df[gram + '_title'].apply(lambda x: [gram_to_idx.get(t) for t in list(set(x.split(' ')))])\n",
    "    df[gram + '_title'] = df[gram + '_title'].apply(lambda x: set([t for t in x if t is not None]))\n",
    "    \n",
    "    \n",
    "    for _,row in df.iterrows():\n",
    "        title_abstract = row[gram + '_title'] | row[gram]\n",
    "        title = row[gram + '_title']\n",
    "        \n",
    "        title_abstract_combs = set(list(it.combinations(title_abstract,2)))\n",
    "        title_combs = set(list(it.combinations(title,2)))\n",
    "                    \n",
    "        baseline.update(title_abstract_combs)\n",
    "        baseline_title.update(title_combs)\n",
    "    \n",
    "\n",
    "print('Exporting title...')\n",
    "\n",
    "writer = open(path_processed + '%s_title_baseline.txt'%(gram_label),'w',  encoding=\"utf-8\")\n",
    "\n",
    "for comb in tqdm(baseline_title, total = len(baseline_title)):\n",
    "    writer.write(str(comb[0]) + ',' + str(comb[1]) + '\\n')\n",
    "    \n",
    "writer.close()\n",
    "\n",
    "print('Exporting title + abstract...')\n",
    "\n",
    "writer = open(path_processed + '%s_baseline.txt'%(gram_label),'w',  encoding=\"utf-8\")\n",
    "\n",
    "for comb in tqdm(baseline, total = len(baseline)):\n",
    "    writer.write(str(comb[0]) + ',' + str(comb[1]) + '\\n')\n",
    "    \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
