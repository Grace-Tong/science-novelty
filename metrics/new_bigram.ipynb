{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86ff862-a28e-45ac-a98c-3e74f9935131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695920c8d8cf40098eecdf06d2e5ae3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "path = 'D:/Users/Nicola Melluso/ScientificPublications/'\n",
    "path_vectors = path + 'Papers/TitleAbstract/papers_vectors/'\n",
    "\n",
    "path_processed = path + 'PapersProcessed/'\n",
    "\n",
    "gram = 'bigrams'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712052ff-7ac7-4acf-b21b-571a3d9f5261",
   "metadata": {},
   "source": [
    "## ************** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b2bf5-49ab-4b7f-9068-58361dfcb37f",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff465883-9c9d-4f9d-8f16-79e20f262998",
   "metadata": {},
   "source": [
    "### 1. Papers to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c150d52f-25e4-4dba-99af-4dbe285ce90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a09822af547485aa76cda20dc09a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72245396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a88339be6bd4868a3a829407b3ada59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33536292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = open('./data/paperIds.txt','r')\n",
    "paperIds = set()\n",
    "\n",
    "for line in tqdm(reader,total = 72245396):\n",
    "    paperIds.add(int(line.replace('\\n','')))\n",
    "    \n",
    "\n",
    "reader = open('./data/paperIdsNov.txt','r')\n",
    "paperIdsNov = set()\n",
    "\n",
    "for line in tqdm(reader,total = 33536292):\n",
    "    paperIdsNov.add(int(line.replace('\\n','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c594db-8fd1-4d86-9efa-14713c77c9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Gram to idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c68c29b-fbf0-4433-b7af-6d97d9b95eff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd83d0521744cf9a4d8616bd17a5c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = open('./data/%s_to_idx.csv'%(gram.split('_')[0]),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "gram_to_idx = {}\n",
    "\n",
    "for line in tqdm(reader):\n",
    "    \n",
    "    if ',' not in line:\n",
    "        continue\n",
    "        \n",
    "    line = line.split(',')\n",
    "    gram_to_idx[line[0]] = int(line[1].replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759d152-1ce3-44fe-95ce-a61a8ad7794e",
   "metadata": {},
   "source": [
    "### 3. Core analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1476dc-8851-4768-b266-820a01fff2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2edb643fce94daf92ee8d1763d12065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24f6bde6e5743dfa73f1780d4b9c427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103061513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the counter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b827c578d0c4482a33bfc5d9efe9425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6140337 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Reading baseline...')\n",
    "baseline = set()\n",
    "\n",
    "reader = open(path_processed + '%s_baseline.txt'%(gram),'r', encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(reader):\n",
    "    \n",
    "    t = gram_to_idx.get(line.replace('\\n',''))\n",
    "    if t is not None:\n",
    "        baseline.add(t)\n",
    "        \n",
    "print('Analysis...')\n",
    "\n",
    "reader = open(path_processed + '%s.csv'%(gram.split('_')[0]),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_paperId.csv'%(gram,gram),'w', encoding=\"utf-8\")\n",
    "writer.write('gram_idx,PaperId\\n')\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for line in tqdm(reader, total = 103061513):\n",
    "    \n",
    "    line = line.split('\\t')\n",
    "    \n",
    "    paperId = int(line[0])\n",
    "    \n",
    "    if paperId not in paperIds:\n",
    "        continue\n",
    "                \n",
    "    text = set(' '.join(line[1:]).split(' '))\n",
    "    #text = set(line[1].split(' '))\n",
    "    text = [gram_to_idx.get(t) for t in text]\n",
    "    text = [t for t in text if ((t is not None) & (t not in baseline))]\n",
    "    \n",
    "    for token in text:\n",
    "        if token not in counter:\n",
    "            if paperId not in paperIdsNov:\n",
    "                continue\n",
    "            \n",
    "            counter[token] = 0\n",
    "            \n",
    "            ## write the PaperId\n",
    "            writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    token,\n",
    "                    paperId\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "        else:\n",
    "            counter[token] += 1\n",
    "    \n",
    "print('Exporting the counter...')\n",
    "writer = open('./data/new_%s/new_%s_reuse.csv'%(gram,gram),'w', encoding=\"utf-8\")\n",
    "writer.write('gram_idx,reuse\\n')\n",
    "\n",
    "for token,reuse in tqdm(counter.items(), total = len(counter)):\n",
    "    writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    token,\n",
    "                    reuse\n",
    "                ]\n",
    "            ]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795df3a9-ba49-47f0-9e73-9153bb5165cf",
   "metadata": {},
   "source": [
    "## 2. Adjust non-doi and citations minimum count "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626e6b9-d4d0-4052-9b3d-645660bd60d1",
   "metadata": {},
   "source": [
    "#### Read grams with only reuse < 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f89a58-6a48-4b7b-b3d1-6f3bfeac0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661d9aa8ddf5450f970dcc8e5ba41d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = set()\n",
    "tokens = set()\n",
    "\n",
    "reader = open('./data/new_%s/new_%s_reuse.csv'%(gram,gram),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "for line in tqdm(reader):\n",
    "    line = line.split(',')\n",
    "    \n",
    "    reuse = int(line[1].replace('\\n',''))\n",
    "    \n",
    "    if reuse <= 5:\n",
    "        continue\n",
    "        \n",
    "    token = int(line[0])\n",
    "    \n",
    "    tokens.add(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfb4b9-41cf-4bf1-a3aa-f42555573531",
   "metadata": {},
   "source": [
    "`tokens` contains all tokens with reuse > 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b5975-443e-4e3c-9377-0c1c8139363c",
   "metadata": {},
   "source": [
    "### Re-do analysis \n",
    "\n",
    "Create a new file `new_gram_PaperId_DC.csv` with the real PaperIds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f7f2ca-065e-49c0-8774-cb428e9ac9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f64df37ea14d42b91394e862f19761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2acbff344564a0f87f31ec950b56be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103061513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the counter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b911e832fb54b009a6dee7b67d0e3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4118839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Reading baseline...')\n",
    "baseline = set()\n",
    "dones = set()\n",
    "counter = Counter()\n",
    "\n",
    "reader = open(path_processed + '%s_baseline.txt'%(gram),'r', encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(reader):\n",
    "    \n",
    "    t = gram_to_idx.get(line.replace('\\n',''))\n",
    "    if t is not None:\n",
    "        baseline.add(t)\n",
    "        \n",
    "print('Analysis...')\n",
    "\n",
    "reader = open(path_processed + '%s.csv'%(gram.split('_')[0]),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_paperId_DC.csv'%(gram,gram),'w', encoding=\"utf-8\")\n",
    "writer.write('gram_idx,PaperId\\n')\n",
    "\n",
    "\n",
    "for line in tqdm(reader, total = 103061513):\n",
    "    \n",
    "    line = line.split('\\t')\n",
    "    \n",
    "    paperId = int(line[0])\n",
    "    \n",
    "    if paperId not in paperIds:\n",
    "        continue\n",
    "                \n",
    "    text = set(' '.join(line[1:]).split(' '))\n",
    "    #text = set(line[1].split(' '))\n",
    "    text = [gram_to_idx.get(t) for t in text]\n",
    "    text = [t for t in text if ((t is not None) & (t not in baseline))]\n",
    "    \n",
    "    for token in text:\n",
    "        if token not in tokens:\n",
    "            if token not in counter:\n",
    "            \n",
    "                ## write the PaperId real\n",
    "                writer.write(','.join([\n",
    "                    str(i) for i in [\n",
    "                        token,\n",
    "                        paperId\n",
    "                    ]\n",
    "                ]) + '\\n')\n",
    "                \n",
    "                counter[token] = 0\n",
    "            else:\n",
    "                counter[token] += 1\n",
    "\n",
    "writer.close()\n",
    "reader.close()\n",
    "\n",
    "\n",
    "print('Exporting the counter...')\n",
    "writer = open('./data/new_%s/new_%s_reuse_DC.csv'%(gram,gram),'w', encoding=\"utf-8\")\n",
    "writer.write('gram_idx,reuse\\n')\n",
    "\n",
    "for token,reuse in tqdm(counter.items(), total = len(counter)):\n",
    "    writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    token,\n",
    "                    reuse\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "    \n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bfeb08-7ca6-4104-b164-070722a6e5a7",
   "metadata": {},
   "source": [
    "# ********* Re-start kernel ********** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9becb719-d145-48ce-9e28-8272238958be",
   "metadata": {},
   "source": [
    "# Aggregations \n",
    "### To execute after the counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2d722-592a-4145-88a2-1f849abd66d7",
   "metadata": {},
   "source": [
    "Chunking strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02ec349-04aa-40bf-8653-b98f1d12c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6f8bdd482144f4bb9fa5d8b28a21ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reader = open('./data/%s_to_idx.csv'%(gram.replace('_title','')),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "idx_to_gram = {}\n",
    "\n",
    "for line in tqdm(reader):\n",
    "    \n",
    "    if ',' not in line:\n",
    "        continue\n",
    "        \n",
    "    line = line.split(',')\n",
    "    idx_to_gram[int(line[1].replace('\\n',''))] = line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557d15f-f513-4a22-9026-a031c765e143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First iterate over all...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c473f92f045f88817b7766c3785e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second iterate over non-DOI and citation minimum...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4c5d2e03824540a920b967e6d2e9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunksize = 500000\n",
    "\n",
    "ds_paperId = pd.read_csv('./data/new_%s/new_%s_paperId.csv'%(gram,gram), chunksize = chunksize, converters = {'PaperId':int,'gram_idx':int}, encoding=\"utf-8\")\n",
    "\n",
    "writer = open('./data/new_%s/new_%s.csv'%(gram,gram),'w', encoding=\"utf-8\")\n",
    "writer.write('%s,PaperId,reuse\\n'%(gram))\n",
    "writer.close()\n",
    "\n",
    "\n",
    "print('First iterate over all...')\n",
    "# iterate over paperIds\n",
    "for df_paperId in tqdm(ds_paperId):\n",
    "    \n",
    "    \n",
    "    to_do_ids = list(df_paperId['PaperId'].unique())\n",
    "    \n",
    "    if to_do_ids == set():\n",
    "        continue\n",
    "\n",
    "    ds_reuse = pd.read_csv('./data/new_%s/new_%s_reuse.csv'%(gram,gram), chunksize = chunksize, converters = {'PaperId':int,'gram_idx':int}, encoding=\"utf-8\")\n",
    "\n",
    "    for df_reuse in ds_reuse:\n",
    "        \n",
    "        df_reuse = df_reuse[df_reuse['reuse'] > 5]\n",
    "        \n",
    "        df = pd.merge(df_paperId,df_reuse, on = 'gram_idx')\n",
    "                    \n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df[gram] = df['gram_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        df = df[[gram,'PaperId','reuse']]\n",
    "        df.to_csv('./data/new_%s/new_%s.csv'%(gram,gram), mode = 'a', header = False, index = False)\n",
    "        \n",
    "        dones_ids = set(df['PaperId'].unique())\n",
    "        \n",
    "        to_do_ids = to_do_ids - dones_ids\n",
    "        \n",
    "        if to_do_ids == set():\n",
    "            break\n",
    "\n",
    "    \n",
    "print('Second iterate over non-DOI and citation minimum...')\n",
    "\n",
    "ds_paperId_DC = pd.read_csv('./data/new_%s/new_%s_paperId_DC.csv'%(gram,gram), chunksize = chunksize, converters = {'PaperId':int,'gram_idx':int},  encoding=\"utf-8\")\n",
    "\n",
    "for df_paperId_DC in tqdm(ds_paperId_DC):\n",
    "    \n",
    "    to_do_ids = list(df_paperId_DC['PaperId'].unique())\n",
    "    \n",
    "    if to_do_ids == set():\n",
    "        continue\n",
    "\n",
    "    ds_reuse = pd.read_csv('./data/new_%s/new_%s_reuse_DC.csv'%(gram,gram), chunksize = chunksize, converters = {'PaperId':int,'gram_idx':int}, encoding=\"utf-8\")\n",
    "\n",
    "    for df_reuse in ds_reuse:\n",
    "        \n",
    "        df_reuse = df_reuse[df_reuse['reuse'] > 0]\n",
    "        \n",
    "        df = pd.merge(df_paperId_DC,df_reuse, on = 'gram_idx')\n",
    "        \n",
    "        \n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        df[gram] = df['gram_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        df = df[[gram,'PaperId','reuse']]\n",
    "        df.to_csv('./data/new_%s/new_%s.csv'%(gram,gram), mode = 'a', header = False, index = False)  \n",
    "        \n",
    "        dones_ids = set(df['PaperId'].unique())\n",
    "        \n",
    "        to_do_ids = to_do_ids - dones_ids\n",
    "        \n",
    "        if to_do_ids == set():\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab64d20a-2146-4b67-8fcd-9e22ee566105",
   "metadata": {},
   "source": [
    "## Memory intensive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880b16b9-ca39-4578-8c70-b9abe059c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First iteration...\n",
      "\tReading combs reuse...\n",
      "\tReading combs paperId...\n",
      "\tConverting PaperId...\n",
      "\tMerging...\n",
      "\tConverting grams...\n",
      "\tExporting...\n",
      "Second iteration...\n",
      "\tReading combs reuse...\n",
      "\tReading combs paperId...\n",
      "\tConverting PaperId...\n",
      "\tMerging...\n",
      "\tConverting grams...\n",
      "\tExporting...\n"
     ]
    }
   ],
   "source": [
    "gram_label = 'bigrams'\n",
    "gram = 'bigrams'\n",
    "\n",
    "print('First iteration...')\n",
    "\n",
    "print('\\tReading combs reuse...')\n",
    "df_reuse = pd.read_csv('./data/new_%s/new_%s_reuse.csv'%(gram,gram), converters={'PaperId': int, 'gram_idx':int,'reuse': int},  encoding=\"utf-8\")\n",
    "df_reuse = df_reuse[df_reuse['reuse'] > 5]\n",
    "\n",
    "print('\\tReading combs paperId...')\n",
    "df_paperId = pd.read_csv('./data/new_%s/new_%s_paperId.csv'%(gram,gram), converters = {'PaperId':int, 'gram_idx':int},  encoding=\"utf-8\")\n",
    "print('\\tConverting PaperId...')\n",
    "\n",
    "print('\\tMerging...')\n",
    "df = pd.merge(df_paperId,df_reuse, on = ['gram_idx'])\n",
    "\n",
    "print('\\tConverting grams...')\n",
    "df[gram] = df['gram_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "df = df[[gram,'PaperId','reuse']]\n",
    "\n",
    "print('\\tExporting...')\n",
    "df.to_csv('./data/new_%s/new_%s.csv'%(gram,gram), index = False)\n",
    "\n",
    "\n",
    "print('Second iteration...')\n",
    "\n",
    "print('\\tReading combs reuse...')\n",
    "df_reuse = pd.read_csv('./data/new_%s/new_%s_reuse_DC.csv'%(gram,gram), converters={'PaperId': int, 'gram_idx':int,'reuse': int},  encoding=\"utf-8\")\n",
    "df_reuse = df_reuse[df_reuse['reuse'] > 0]\n",
    "\n",
    "print('\\tReading combs paperId...')\n",
    "df_paperId = pd.read_csv('./data/new_%s/new_%s_paperId_DC.csv'%(gram,gram), converters = {'PaperId':int, 'gram_idx':int},  encoding=\"utf-8\")\n",
    "print('\\tConverting PaperId...')\n",
    "\n",
    "print('\\tMerging...')\n",
    "df = pd.merge(df_paperId,df_reuse, on = ['gram_idx'])\n",
    "\n",
    "print('\\tConverting grams...')\n",
    "df[gram] = df['gram_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "df = df[[gram,'PaperId','reuse']]\n",
    "\n",
    "print('\\tExporting...')\n",
    "df.to_csv('./data/new_%s/new_%s.csv'%(gram,gram), mode = 'a', header = False, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e075e1b8-237a-4f2b-9f22-85f7673f5454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigrams</th>\n",
       "      <th>PaperId</th>\n",
       "      <th>reuse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104533</th>\n",
       "      <td>risk_factor</td>\n",
       "      <td>2320162370</td>\n",
       "      <td>685806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154695</th>\n",
       "      <td>electron_microscopy</td>\n",
       "      <td>2058067835</td>\n",
       "      <td>627244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>amino_acid</td>\n",
       "      <td>2319189718</td>\n",
       "      <td>564656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117083</th>\n",
       "      <td>gene_expression</td>\n",
       "      <td>2079639548</td>\n",
       "      <td>474777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21082</th>\n",
       "      <td>x-ray_diffraction</td>\n",
       "      <td>2162267393</td>\n",
       "      <td>469012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564871</th>\n",
       "      <td>ln_reaction</td>\n",
       "      <td>1967514966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564875</th>\n",
       "      <td>stark_denial</td>\n",
       "      <td>1971613808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564876</th>\n",
       "      <td>prophylactic_amulet</td>\n",
       "      <td>2000879805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564880</th>\n",
       "      <td>destination_originate</td>\n",
       "      <td>2039694185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32104335</th>\n",
       "      <td>cilastatin_imi</td>\n",
       "      <td>3119785277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32104336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        bigrams     PaperId   reuse\n",
       "104533              risk_factor  2320162370  685806\n",
       "154695      electron_microscopy  2058067835  627244\n",
       "5390                 amino_acid  2319189718  564656\n",
       "117083          gene_expression  2079639548  474777\n",
       "21082         x-ray_diffraction  2162267393  469012\n",
       "...                         ...         ...     ...\n",
       "19564871            ln_reaction  1967514966       1\n",
       "19564875           stark_denial  1971613808       1\n",
       "19564876    prophylactic_amulet  2000879805       1\n",
       "19564880  destination_originate  2039694185       1\n",
       "32104335         cilastatin_imi  3119785277       1\n",
       "\n",
       "[32104336 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/new_%s/new_%s.csv'%(gram,gram))\n",
    "df = df.sort_values(by = 'reuse', ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f8cd3a-589f-483c-b8c9-9188fe34c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [gram]).drop_duplicates(subset = [gram]).to_csv('./data/new_%s/new_%s.csv'%(gram,gram), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fefa95-7475-4a09-a629-bb0c3a881cf3",
   "metadata": {},
   "source": [
    "#### Furthering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8174966d-b412-4150-8d46-b419b97dda6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigrams</th>\n",
       "      <th>PaperId</th>\n",
       "      <th>reuse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6419415</th>\n",
       "      <td>islamicthought</td>\n",
       "      <td>28663574</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186245</th>\n",
       "      <td>islamicthought</td>\n",
       "      <td>1518979411</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874531</th>\n",
       "      <td>linguo-pragmatic</td>\n",
       "      <td>2325714478</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186247</th>\n",
       "      <td>linguo-pragmatic</td>\n",
       "      <td>3116209162</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917450</th>\n",
       "      <td>nomenklatorische</td>\n",
       "      <td>2185152724</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186246</th>\n",
       "      <td>nomenklatorische</td>\n",
       "      <td>2799440834</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186244</th>\n",
       "      <td>pfizer-biontech</td>\n",
       "      <td>3111015982</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304868</th>\n",
       "      <td>pfizer-biontech</td>\n",
       "      <td>3111015982</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304739</th>\n",
       "      <td>v11i21</td>\n",
       "      <td>3107086491</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186243</th>\n",
       "      <td>v11i21</td>\n",
       "      <td>3107960907</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1785752228</td>\n",
       "      <td>20782161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354077</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2044068044</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 unigrams     PaperId     reuse\n",
       "6419415    islamicthought    28663574        12\n",
       "3186245    islamicthought  1518979411         4\n",
       "6874531  linguo-pragmatic  2325714478        11\n",
       "3186247  linguo-pragmatic  3116209162         3\n",
       "4917450  nomenklatorische  2185152724         8\n",
       "3186246  nomenklatorische  2799440834         4\n",
       "3186244   pfizer-biontech  3111015982         5\n",
       "7304868   pfizer-biontech  3111015982         5\n",
       "7304739            v11i21  3107086491         8\n",
       "3186243            v11i21  3107960907         6\n",
       "3                     NaN  1785752228  20782161\n",
       "354077                NaN  2044068044       818"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[gram].duplicated(keep = False)].sort_values(by = gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7eb7945-3a05-4a8c-8e7c-f3ab5a4f77a8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigrams</th>\n",
       "      <th>PaperId</th>\n",
       "      <th>reuse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3479939</th>\n",
       "      <td>ristime</td>\n",
       "      <td>2090274089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7760831</th>\n",
       "      <td>tmpgde-crosslinked</td>\n",
       "      <td>2292116333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773863</th>\n",
       "      <td>esprcially</td>\n",
       "      <td>2313326836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429942</th>\n",
       "      <td>akkemansia</td>\n",
       "      <td>3041041889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837923</th>\n",
       "      <td>gorsellerde</td>\n",
       "      <td>2532724368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177746</th>\n",
       "      <td>kpca-rvm</td>\n",
       "      <td>1961641524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177744</th>\n",
       "      <td>cx43-downregulated</td>\n",
       "      <td>2029086396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4561113</th>\n",
       "      <td>hippocrates-galen</td>\n",
       "      <td>1972020073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177730</th>\n",
       "      <td>excutation</td>\n",
       "      <td>2267198292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495540</th>\n",
       "      <td>p0a0</td>\n",
       "      <td>3117013959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190455 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   unigrams     PaperId  reuse\n",
       "3479939             ristime  2090274089      0\n",
       "7760831  tmpgde-crosslinked  2292116333      0\n",
       "3773863          esprcially  2313326836      0\n",
       "8429942          akkemansia  3041041889      0\n",
       "7837923         gorsellerde  2532724368      0\n",
       "...                     ...         ...    ...\n",
       "7177746            kpca-rvm  1961641524      0\n",
       "7177744  cx43-downregulated  2029086396      0\n",
       "4561113   hippocrates-galen  1972020073      0\n",
       "7177730          excutation  2267198292      0\n",
       "8495540                p0a0  3117013959      0\n",
       "\n",
       "[1190455 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert df[df['reuse'] == 0].empty\n",
    "assert df.shape[0] == df.drop_duplicates(subset = gram).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249deef7-fefe-4230-96a0-3dd7478e407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [gram]).to_csv('./data/new_%s/new_%s.csv'%(gram,gram), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
