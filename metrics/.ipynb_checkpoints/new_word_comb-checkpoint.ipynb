{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86ff862-a28e-45ac-a98c-3e74f9935131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b383579c3c40d297a4177171775a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm().pandas()\n",
    "import numpy as np\n",
    "\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712052ff-7ac7-4acf-b21b-571a3d9f5261",
   "metadata": {},
   "source": [
    "## ************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe1476dc-8851-4768-b266-820a01fff2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading baseline...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af9d05cdc2943ebb05df3b7dfda4034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10809447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2d22f565da4ebabc89906c2a4ee17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10172374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808812a11c494b689a83d7bb5f058f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103061513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting the counter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e44909a9264728a951d56fe9c8de57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2579272666 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Reading baseline...')\n",
    "baseline = set()\n",
    "\n",
    "reader = open(path_processed + '%s_baseline.txt'%(gram_label),'r', encoding=\"utf-8\")\n",
    "\n",
    "for line in tqdm(reader, total = 10809447):\n",
    "    \n",
    "    baseline.add(tuple(sorted([int(i) for i in line.replace('\\n','').split(',')])))\n",
    "\n",
    "# remove empty space combinations\n",
    "baseline = set([i for i in tqdm(baseline) if 1 not in i])\n",
    "        \n",
    "print('Analysis...')\n",
    "\n",
    "reader = open('./data/%s.csv'%(gram.split('_')[0]),'r', encoding=\"utf-8\")\n",
    "reader.__next__()\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_paperId.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,PaperId\\n')\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for line in tqdm(reader, total = 103061513):\n",
    "    \n",
    "    line = line.split('\\t')\n",
    "    \n",
    "    paperId = int(line[0])\n",
    "    \n",
    "    if paperId not in paperIds:\n",
    "        continue\n",
    "                \n",
    "    text = set(' '.join(line[1:]).split(' '))\n",
    "    text = [gram_to_idx.get(t) for t in text]\n",
    "    text = set([t for t in text if t is not None])\n",
    "\n",
    "    combs = list(it.combinations(text,2))\n",
    "\n",
    "    combs = [c for c in combs if c not in baseline]\n",
    "    \n",
    "    for comb in combs:\n",
    "        comb = tuple(sorted(comb))\n",
    "        if comb not in counter:\n",
    "            if paperId not in paperIdsNov:\n",
    "                continue\n",
    "            \n",
    "            counter[comb] = 0\n",
    "            \n",
    "            ## write the PaperId\n",
    "            writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    comb[0],\n",
    "                    comb[1],\n",
    "                    paperId\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "        else:\n",
    "            counter[comb] += 1\n",
    "            \n",
    "writer.close()\n",
    "    \n",
    "print('Exporting the counter...')\n",
    "writer = open('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label),'w', encoding=\"utf-8\")\n",
    "writer.write('gram1_idx,gram2_idx,reuse\\n')\n",
    "\n",
    "for comb,reuse in tqdm(counter.items(), total = len(counter)):\n",
    "    writer.write(','.join([\n",
    "                str(i) for i in [\n",
    "                    comb[0],\n",
    "                    comb[1],\n",
    "                    reuse\n",
    "                ]\n",
    "            ]) + '\\n')\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9557d15f-f513-4a22-9026-a031c765e143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First iterate over all...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43b111d080443f9ba5628a79826d263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b22fe5fc15e4777b0075048f3e45c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'paperIds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df_paperId,df_reuse, on \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgram1_idx\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgram2_idx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     34\u001b[0m dones_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaperId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m---> 36\u001b[0m df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m|\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[43mpaperIds\u001b[49m))]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paperIds' is not defined"
     ]
    }
   ],
   "source": [
    "chunksize = 1000000000\n",
    "\n",
    "ds_paperId = pd.read_csv('./data/new_%s/new_%s_paperId.csv'%(gram_label,gram_label), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "writer = open('./data/new_%s/new_%s_2.csv'%(gram_label,gram_label),'w')\n",
    "writer.write('word1,word2,PaperId,reuse\\n')\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "print('First iterate over all...')\n",
    "# iterate over paperIds\n",
    "for df_paperId in tqdm(ds_paperId, total = round(2579272666/chunksize)):\n",
    "    \n",
    "    reuses_dones = [-1]\n",
    "    \n",
    "    to_do_ids = set(list(df_paperId['PaperId'].unique()))\n",
    "    \n",
    "    if to_do_ids == set():\n",
    "        continue\n",
    "\n",
    "    ds_reuse = pd.read_csv('./data/new_%s/new_%s_reuse.csv'%(gram_label,gram_label), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "        \n",
    "    for i_reuse,df_reuse in tqdm(enumerate(ds_reuse)):\n",
    "        \n",
    "        if i_reuse <= max(reuses_dones):\n",
    "            continue\n",
    "        \n",
    "        #df_reuse = df_reuse[(df_reuse['reuse'] > 5) | (df_reuse['reuse'].isin(paperIds))]\n",
    "        \n",
    "        df = pd.merge(df_paperId,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "        \n",
    "        dones_ids = set(df['PaperId'].unique())\n",
    "        \n",
    "        df = df[(df['reuse'] > 5) | (df['reuse'].isin(paperIds))]\n",
    "                    \n",
    "        if df.empty:\n",
    "            continue\n",
    "            \n",
    "\n",
    "        df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "        df = df[['word1','word2','PaperId','reuse']]\n",
    "\n",
    "        df.to_csv('./data/new_%s/new_%s.csv'%(gram_label,gram_label), mode = 'a', header = False, index = False)\n",
    "        \n",
    "        \n",
    "        to_do_ids = to_do_ids - dones_ids\n",
    "\n",
    "        if to_do_ids == set():\n",
    "            reuses_dones.append(i_reuse)\n",
    "            break\n",
    "    \n",
    "print('Second iterate over non-DOI and citation minimum...')\n",
    "\n",
    "ds_paperId_DC = pd.read_csv('./data/new_%s/new_%s_paperId_DC.csv'%(gram_label,gram_label), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "\n",
    "for df_paperId_DC in tqdm(ds_paperId_DC, total = round(2863311530/chunksize)):\n",
    "    \n",
    "    reuses_dones = [-1]\n",
    "    \n",
    "    to_do_ids = set(list(df_paperId_DC['PaperId'].unique()))\n",
    "    \n",
    "    if to_do_ids == set():\n",
    "        continue\n",
    "    \n",
    "    ds_reuse = pd.read_csv('./data/new_%s/new_%s_reuse_DC.csv'%(gram,gram), chunksize = chunksize, converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int}, encoding=\"utf-8\")\n",
    "    \n",
    "    for i_reuse, df_reuse in tqdm(enumerate(ds_reuse)):\n",
    "        \n",
    "        if i_reuse <= max(reuses_dones):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        df = pd.merge(df_paperId_DC,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "        \n",
    "        dones_ids = set(df['PaperId'].unique())\n",
    "        \n",
    "        df = df[df['reuse'] > 0]\n",
    "        \n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "        \n",
    "        df = df[['word1','word2','PaperId','reuse']]\n",
    "        \n",
    "        df.to_csv('./data/new_%s/new_%s.csv'%(gram_label,gram_label), mode = 'a', header = False, index = False)     \n",
    "        \n",
    "        \n",
    "        to_do_ids = to_do_ids - dones_ids\n",
    "        \n",
    "        if to_do_ids == set():\n",
    "            reuses_dones.append(i_reuse)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4a2167-f58e-4473-8202-be665e9650e6",
   "metadata": {},
   "source": [
    "#### 2nd iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09da29-55ad-4978-af25-a2ec2628b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading combs reuse...')\n",
    "df_reuse = pd.read_csv('./data/new_%s/new_%s_reuse_DC.csv'%(gram_label,gram_label), converters={'PaperId': int, 'gram1_idx':int, 'gram2_idx':int, 'reuse': int},  encoding=\"utf-8\")\n",
    "df_reuse = df_reuse[df_reuse['reuse'] > 0]\n",
    "\n",
    "print('Reading combs paperId...')\n",
    "df_paperId = pd.read_csv('./data/new_%s/new_%s_paperId_DC.csv'%(gram_label,gram_label), converters = {'PaperId':int,'gram1_idx':int, 'gram2_idx':int},  encoding=\"utf-8\")\n",
    "print('Converting PaperId...')\n",
    "\n",
    "print('Merging...')\n",
    "df = pd.merge(df_paperId,df_reuse, on = ['gram1_idx','gram2_idx'])\n",
    "\n",
    "print('Converting grams...')\n",
    "df['word1'] = df['gram1_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "df['word2'] = df['gram2_idx'].apply(lambda x: idx_to_gram.get(x))\n",
    "\n",
    "df = df[['word1','word2','PaperId','reuse']]\n",
    "\n",
    "print('Exporting...')\n",
    "df.to_csv('./data/new_%s/new_%s_2.csv'%(gram_label,gram_label), mode = 'a', header = False, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea810eeb-92bb-4ee7-84ed-7c759266482e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = range(1880,1901)\n",
    "\n",
    "baseline = set()\n",
    "baseline_title = set()\n",
    "\n",
    "for year in tqdm(years, total = len(years)):\n",
    "    df = pd.read_parquet(path_processed + gram + '/%d.parquet'%(year))\n",
    "    \n",
    "    df = df[df['Flag'] == 'Green'].fillna('')\n",
    "    \n",
    "    df[gram] = df[gram].apply(lambda x: [gram_to_idx.get(t) for t in list(set(x.split(' ')))])\n",
    "    df[gram] = df[gram].apply(lambda x: set([t for t in x if t is not None]))\n",
    "    \n",
    "    df[gram + '_title'] = df[gram + '_title'].apply(lambda x: [gram_to_idx.get(t) for t in list(set(x.split(' ')))])\n",
    "    df[gram + '_title'] = df[gram + '_title'].apply(lambda x: set([t for t in x if t is not None]))\n",
    "    \n",
    "    \n",
    "    for _,row in df.iterrows():\n",
    "        title_abstract = row[gram + '_title'] | row[gram]\n",
    "        title = row[gram + '_title']\n",
    "        \n",
    "        title_abstract_combs = set(list(it.combinations(title_abstract,2)))\n",
    "        title_combs = set(list(it.combinations(title,2)))\n",
    "                    \n",
    "        baseline.update(title_abstract_combs)\n",
    "        baseline_title.update(title_combs)\n",
    "    \n",
    "\n",
    "print('Exporting title...')\n",
    "\n",
    "writer = open(path_processed + '%s_title_baseline.txt'%(gram_label),'w',  encoding=\"utf-8\")\n",
    "\n",
    "for comb in tqdm(baseline_title, total = len(baseline_title)):\n",
    "    writer.write(str(comb[0]) + ',' + str(comb[1]) + '\\n')\n",
    "    \n",
    "writer.close()\n",
    "\n",
    "print('Exporting title + abstract...')\n",
    "\n",
    "writer = open(path_processed + '%s_baseline.txt'%(gram_label),'w',  encoding=\"utf-8\")\n",
    "\n",
    "for comb in tqdm(baseline, total = len(baseline)):\n",
    "    writer.write(str(comb[0]) + ',' + str(comb[1]) + '\\n')\n",
    "    \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
